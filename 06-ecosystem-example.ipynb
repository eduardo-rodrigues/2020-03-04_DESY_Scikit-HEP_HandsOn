{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1><b><span style=\"color:blue\">\"HEP Python ecosystem example\"</span></b></h1></center>\n",
    "\n",
    "#### **\"Thinking outside the box\"**\n",
    "\n",
    "Other groups and projects are working on other domain-specific areas towards the common goal of a modern, Pythonic and friendly analysis ecosystem for HEP. Let's play a bit with the `phasespace` and `zfit` packages from the [zfit project](https://github.com/zfit/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;<br><center><img src=\"images/logo_zfit.png\" alt=\"zfit package logo\" style=\"width: 200px;\"/></center>\n",
    "\n",
    "<center><h2><b><span style=\"color:green\">Model building and fitting library based on TensorFlow</span></b></h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `zfit` package is a model fitting library based on TensorFlow and optimised for simple and direct manipulation of probability density functions. The main focus is on the scalability, parallelisation and a Pythonic user friendly experience framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **A HEP common usecase - simultaneoous fit to a signal decay and a control mode**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "<b>Acknowledgements:</b>\n",
    "\n",
    "This tutorial is largely based on code kindly provided by Jonas Eschle (University of Zurich).\n",
    "It showcases the generation and fit of samples of $ B \\to K^* \\mu^+ \\mu^-$ events,\n",
    "including a simultaneous, and the subsequent determination of the signal significance.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unbinned maximum likelihood model fit to $B^0 \\to \\mu^+ \\mu^- K^{*0}$\n",
    "\n",
    "The fit will be done in three steps using the `zfit` package:\n",
    "- a fit with the exponential to the right side to have a good starting value.\n",
    "- a model composed of an exponential for the combinatorial bkg and a double Crystalball for the $B^0 \\to \\mu^+ \\mu^- K^{*0}$ signal is built and fitted to the \"rare\" mode. This is hard to get right, as we have low statistics in the rare mode.\n",
    "- To improve the fit, the same model with a few shared parameters is built for the resonant mode $B^0 \\to J/\\psi (\\to \\mu^+ \\mu^-) K^{*0}$\n",
    "  to improve the shape of the DoubleCB, as mostly the tails are tricky. They seem to be independent of q2, so we can share them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **0. Imports, settings, helper functions**\n",
    "\n",
    "Let's start by importing\n",
    "- Standard library modules\n",
    "- Scikit-HEP packages\n",
    "- `phasespace` and `zfit`\n",
    "\n",
    "... this is what is meant by working with an ecosystem ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from particle.particle import literals as lp\n",
    "from hepstats import hypotests\n",
    "\n",
    "from phasespace import GenParticle\n",
    "\n",
    "import os\n",
    "os.environ['ZFIT_DISABLE_TF_WARNINGS'] = \"True\"  # suppresses TensorFlow warnings\n",
    "import zfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General settings:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 11  # a \"good\" seed\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "B0_MASS = lp.B_0.mass\n",
    "JPSI_MASS = lp.Jpsi_1S.mass\n",
    "KSTARZ_MASS = lp.Kst_892_0.mass\n",
    "KSTARZ_WIDTH = lp.Kst_892_0.width\n",
    "PION_MASS = lp.pi_minus.mass\n",
    "KAON_MASS = lp.K_plus.mass\n",
    "MU_MASS = lp.mu_minus.mass\n",
    "\n",
    "# Yields - feel free to change these to play around\n",
    "n_sig_rare = 120\n",
    "n_sig_reso = 4000\n",
    "n_bkg_rare = 5000\n",
    "n_bkg_reso = 3000\n",
    "\n",
    "# Detector smearing of the particles 4-momenta (sigma of a Gaussian)\n",
    "rare_smearing = 7\n",
    "reso_smearing = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invariant_mass(four_momenta):\n",
    "    \"\"\"Calculate the invariant mass given a four momenta with shape (n_events, 4) with px, py, pz, E.\"\"\"\n",
    "    momenta_squared = four_momenta ** 2\n",
    "    return np.sqrt(momenta_squared[:, 3] - np.sum((momenta_squared[:, :3]), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since this is kinematically sampled from a fixed B mass, currently the reconstructed invariant B mass would only\n",
    "# be a sharp peak. To include detector resolution effects and make it look more like real data/MC,\n",
    "# the particles are smeared (similar to what RapidSim does).\n",
    "def smear_momenta(four_momenta, smearing=10):\n",
    "    \"\"\"Smears the momenta (gaussian) with a width of `smearing`.\"\"\"\n",
    "    # The four_momenta are \"eager_tensors\", wrapped numpy arrays. \n",
    "    # We could convert them with `np.array(four_momenta)`\n",
    "    return np.random.normal(loc=four_momenta, scale=smearing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Phasespace generation of the rare signal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To generate the signal, we will sample from the phasespace of the decay and apply some ad-hoc smearing.\n",
    "# Using the phasespace package, a decay chain has to be sticked together with the different particles.\n",
    "# While this is simple to do for non-resonant particles with a fixed mass, since it is only a number,\n",
    "# phasespace allows also for (arbitrary) resonance shapes of the mass. Therefor, instead of a constant number,\n",
    "# a function that samples from the resonance can be provided, whereby min_mass, max_mass specify the kinematically\n",
    "# allowed boundaries for the mass. This is best illustrated with the example below\n",
    "\n",
    "# K* is resonant, we define here the sampling of the mass.\n",
    "# Either zfit PDFs or TensorFlow Probability distributions (or anything using TensorFlow, also arbitrary\n",
    "# Python functions wrappet with `tf.py_function`, can be used). White TensorFlow Probability offers many usefule\n",
    "# distributions, they often have support from -inf to inf, while zfit PDFs offer the possitility to sample only\n",
    "# within certain limits.\n",
    "\n",
    "\n",
    "def kstar_mass(min_mass, max_mass, n_events):\n",
    "    # make sure everything is float64\n",
    "    min_mass = tf.cast(min_mass, tf.float64)\n",
    "    max_mass = tf.cast(max_mass, tf.float64)\n",
    "    kstar_width_cast = tf.cast(KSTARZ_WIDTH, tf.float64)\n",
    "    kstar_mass_cast = tf.cast(KSTARZ_MASS, dtype=tf.float64)\n",
    "\n",
    "    # To produce n_events samples, we can e.g. broadcast the K* mass (currently a scalar)\n",
    "    # to have the right shape (n_events,). But there are many ways, also see TensorFlow Probability Distributions\n",
    "    kstar_mass = tf.broadcast_to(kstar_mass_cast, shape=(n_events,))\n",
    "    if KSTARZ_WIDTH > 0:\n",
    "        kstar_mass = tfp.distributions.TruncatedNormal(loc=kstar_mass,\n",
    "                                                       scale=kstar_width_cast,\n",
    "                                                       low=min_mass,\n",
    "                                                       high=max_mass).sample()\n",
    "    return kstar_mass\n",
    "\n",
    "\n",
    "# create the K* and also set its children.\n",
    "kstar = GenParticle('K*0', mass=kstar_mass).set_children(GenParticle('K+', mass=KAON_MASS),\n",
    "                                                         GenParticle('pi-', mass=PION_MASS))\n",
    "bz = GenParticle('B0', B0_MASS).set_children(kstar,\n",
    "                                             GenParticle('mu+', mass=MU_MASS),\n",
    "                                             GenParticle('mu-', mass=MU_MASS))\n",
    "\n",
    "# `generate` returns the weights of the event and a dict which contains the 4-momenta of the particles\n",
    "# as {particle_name: EagerTensor of shape (n_events, 4)}, where an EagerTensor is basically a wrapped numpy array.\n",
    "# and the particle_name is e.g. 'K+', 'K*0', the name that has been used above.\n",
    "weights, particles = bz.generate(n_sig_rare)\n",
    "weights = weights / np.average(weights)\n",
    "\n",
    "\n",
    "# Since this is kinematically sampled from a fixed B mass, currently the reconstructed invariant B mass would only\n",
    "# be a sharp peak. To include detector resolution effects and make it look more like real data/MC, the particles are smeared.\n",
    "smeared_momenta = {}\n",
    "daugther_particles = ['K+', 'pi-', 'mu+', 'mu-']\n",
    "for particle in daugther_particles:\n",
    "    smeared_momenta[particle] = smear_momenta(particles[particle], smearing=rare_smearing)\n",
    "\n",
    "# reconstruct the mother particles using the smeared daughters\n",
    "smeared_momenta['K*0'] = smeared_momenta['K+'] + smeared_momenta['pi-']\n",
    "smeared_momenta['Jpsi'] = smeared_momenta['mu+'] + smeared_momenta['mu-']\n",
    "smeared_momenta['B0'] = smeared_momenta['K*0'] + smeared_momenta['Jpsi']\n",
    "\n",
    "b_mass_rare = invariant_mass(smeared_momenta['B0'])\n",
    "q2 = invariant_mass(smeared_momenta['Jpsi']) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualise the spectrum:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be used later\n",
    "xlabel_bmass = 'm($K^+ \\pi^- \\mu^+ \\mu^-$) [MeV/c^2]'\n",
    "\n",
    "# plot the b mass with the weights. It is basically the same as without weights.\n",
    "plt.figure()\n",
    "plt.title(\"B mass generated non resonant\")\n",
    "plt.hist(b_mass_rare, weights=weights, alpha=0.5, bins=40, label=\"with weights\")\n",
    "plt.hist(b_mass_rare, bins=40, alpha=0.5, label=\"no weights\")\n",
    "plt.xlabel('$q^2 (MeV^2/c^4)$')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"q2 generated non resonant\")\n",
    "plt.hist(q2, weights=weights, alpha=0.5, bins=40, label=\"with weights\")\n",
    "plt.hist(q2, bins=40, alpha=0.5, label=\"no weights\")\n",
    "plt.xlabel('$q^2 [MeV^2/c^4]$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Fit to the rare signal**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit will be done in three steps using the zfit package:\n",
    "- a fit with the exponential to the right side to have a good\n",
    "  starting value.\n",
    "- a model composed of an exponential for the combinatorial bkg and a double Crystalball for\n",
    "  the signal is built and fitted to the \"rare\" mode. This is hard to get right, as we have low\n",
    "  statistics in the rare mode.\n",
    "- To improve the fit, the same model with a few shared parameters is built for the resonant mode\n",
    "  to improve the shape of the DoubleCB, as moslty the tails are tricky. They seem to be independent\n",
    "  of q2, so we can share them\n",
    "\n",
    "#### If the fit does not converge\n",
    "\n",
    "Finding the minimum given some parameters is in general not a simple problem. Two major reasons this does\n",
    "not work well are the initial values and the step_size that are too far off or too large/small. The latter\n",
    "should be around the uncertainty of the parameter (once the fit will be converged). More information can be\n",
    "found here: https://github.com/zfit/zfit/wiki/FAQ#fitting-and-minimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.a Fit to the right-hand sideband**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firstly, the observable and its range is defined\n",
    "upper_limit = 5600\n",
    "obs = zfit.Space('Bmass', (5000, upper_limit))  # for whole range\n",
    "obs_bkg = zfit.Space('Bmass', (5400, upper_limit))  # to pre-fit the exponential\n",
    "\n",
    "# Parameters are specified:  (name (unique), initial, lower, upper) whereas lower, upper are optional\n",
    "lambda_rare = zfit.Parameter('lambda_rare', -0.002, -0.01, -0.0001, step_size=0.001)  # floating, also without limits\n",
    "comb_bkg_rare = zfit.pdf.Exponential(lambda_rare, obs=obs)\n",
    "\n",
    "# Create some bkg data\n",
    "comb_bkg_rare_sample = comb_bkg_rare.sample(n=n_bkg_rare)  # sampled within the limits of `obs`\n",
    "\n",
    "# To improve the fit, the rightside can first be fitted to the combinatorial background in order to get\n",
    "# a good initial value\n",
    "right_tale_data_rare = zfit.Data.from_numpy(obs=obs_bkg, array=comb_bkg_rare_sample.value())\n",
    "\n",
    "# Set the value of lambda to something different than we sampled from (for the fit afterwards)\n",
    "lambda_rare.set_value(-0.003)\n",
    "\n",
    "# The normalisation range is temporarily set to the right side only\n",
    "with comb_bkg_rare.set_norm_range(obs_bkg):\n",
    "    right_tale_loss = zfit.loss.UnbinnedNLL(comb_bkg_rare, right_tale_data_rare)\n",
    "    minimizer = zfit.minimize.Minuit(verbosity=7, use_minuit_grad=True)\n",
    "    result_right_tale = minimizer.minimize(right_tale_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.b Fit to the full spectrum**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data for the rare fit\n",
    "rare_data_np = np.concatenate([b_mass_rare, comb_bkg_rare_sample[:, 0]], axis=0)\n",
    "rare_weights_np = np.concatenate([weights, np.ones_like(comb_bkg_rare_sample[:, 0])], axis=0)\n",
    "# TODO: we could do some data preprocessing here (e.g. apply a cut to q2, which we actually\n",
    "# need to have \"no Jpsi\" in there). This can be done with pandas and then loaded into zfit\n",
    "\n",
    "rare_data = zfit.Data.from_numpy(obs=obs, array=rare_data_np, weights=rare_weights_np)\n",
    "# Data can also be loaded from ROOT\n",
    "# right_tale_data_rare = zfit.Data.from_root(...)\n",
    "\n",
    "# ...or to/from a pandas DataFrame. Either convert the `zfit.Data` to a pandas DF\n",
    "# right_tale_data_rare_df = right_tale_data_rare.to_pandas()\n",
    "# .... or create it from scratch\n",
    "# right_tale_data_rare_df = pd.DataFrame(data=rare_data_np, columns=obs_bkg.obs)\n",
    "# Then we can directly load it\n",
    "# right_tale_data_rare = zfit.Data.from_pandas(df=right_tale_data_rare_df, obs=obs_bkg)\n",
    "\n",
    "# (maybe remove plot, just for data visualisation example?)\n",
    "plt.figure()\n",
    "plt.title(\"Invariant mass of combinatorial bkg and signal $B^0 -> K^{*} (-> K^+ \\pi^-) \\mu^+ \\mu^-$\")\n",
    "plt.hist(rare_data_np, weights=rare_weights_np, bins=40)\n",
    "plt.xlabel(xlabel_bmass)\n",
    "\n",
    "# Create the model to fit to the rare mode\n",
    "\n",
    "# Parameters for the model\n",
    "mu = zfit.Parameter('mu', 5270, 5200, 5350, step_size=3)\n",
    "sigma = zfit.Parameter('sigma', 22, 0, 100, step_size=0.5)\n",
    "\n",
    "# A double crystalball, a sum of two Crystal Ball functions will be used\n",
    "alphal_rare = zfit.Parameter('alpha left rare', -0.3, -5, 0)\n",
    "nl_rare = zfit.Parameter('n left rare', 0.3, 0, 10)\n",
    "alphar_rare = zfit.Parameter('alpha right rare', 1, 0, 5)\n",
    "nr_rare = zfit.Parameter('n right rare', 2.8, 0, 10)\n",
    "frac_dcb_rare = zfit.Parameter('frac dcb', 0.3, 0.1, 0.9)\n",
    "\n",
    "left_cb_rare = zfit.pdf.CrystalBall(obs=obs,\n",
    "                                    mu=mu, sigma=sigma,\n",
    "                                    alpha=alphal_rare, n=nl_rare,\n",
    "                                    )\n",
    "right_cb_rare = zfit.pdf.CrystalBall(obs=obs,\n",
    "                                     mu=mu, sigma=sigma,\n",
    "                                     alpha=alphar_rare, n=nr_rare,\n",
    "                                     )\n",
    "signal_rare = zfit.pdf.SumPDF([left_cb_rare, right_cb_rare], fracs=frac_dcb_rare)\n",
    "\n",
    "\n",
    "# Create the yields and the extended pdfs\n",
    "rare_sig_yield = zfit.Parameter('rare_sig_yield', n_sig_rare + 30,\n",
    "                                step_size=3)  # step size: default is small, use appropriate\n",
    "rare_bkg_yield = zfit.Parameter('rare_bkg_yield', n_bkg_rare - 40, step_size=1)\n",
    "# Create extended PDFs\n",
    "extended_sig_rare = signal_rare.create_extended(rare_sig_yield)\n",
    "extended_bkg_rare = comb_bkg_rare.create_extended(rare_bkg_yield)\n",
    "\n",
    "# The final model is the combination of the signal and backgrond pdf\n",
    "model_rare = zfit.pdf.SumPDF([extended_bkg_rare, extended_sig_rare])\n",
    "\n",
    "\n",
    "# Different models could be used here. A more simple model, such as a Gaussian...\n",
    "# signal_rare = zfit.pdf.Gauss(mu=mu, sigma=sigma, obs=obs)\n",
    "\n",
    "# ...or even a completely custom PDF. Explained also here: https://zfit.readthedocs.io/en/latest/intro/model.html#custom-pdf\n",
    "# from zfit import z  # backend, can also use TensorFlow directly\n",
    "#\n",
    "# class MySignal(zfit.ZPDF):\n",
    "#     _N_OBS = 1\n",
    "#     _PARAMS = ['mean', 'width']\n",
    "#    \n",
    "#     # Implement the shape (unnormalized) of your pdf. If the analytical integral is known, it can be\n",
    "#     # registered later on.\n",
    "#     def _unnormalized_pdf(self, x):\n",
    "#         x = z.unstack(x)  # could be higher dimensional\n",
    "#         mean = self.params['mean']\n",
    "#         width = self.params['width']\n",
    "#         return z.exp((x - mean) ** 2 / (2 * width ** 2))  # Gaussian, unnormalized\n",
    "#\n",
    "#\n",
    "# signal_rare = MySignal(mean=mu, width=sigma, obs=obs)\n",
    "\n",
    "\n",
    "# In order to plot our model, a helper function is created\n",
    "def plot_pdf_data(data, model, title, n_bins=40):\n",
    "    linewidth = 2.5\n",
    "    space = data.data_range\n",
    "    plot_scaling = data.nevents / n_bins * space.area()\n",
    "    lower, upper = space.limit1d\n",
    "    x = np.linspace(lower, upper, 1000)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "\n",
    "    # plot the data\n",
    "    data_np = data[:, 0]\n",
    "    plt.hist(data_np,\n",
    "             # color=color,\n",
    "             bins=n_bins, histtype=\"stepfilled\", alpha=0.1)\n",
    "    plt.hist(data_np,\n",
    "             # color=color,\n",
    "             bins=n_bins, histtype=\"step\")\n",
    "    # plot the pdfs\n",
    "    y = zfit.run(model.pdf(x))\n",
    "    y_sig = zfit.run(model.pdfs[0].pdf(x) * model.fracs[0])# notice the frac!\n",
    "    y_bkg = zfit.run(model.pdfs[1].pdf(x) * model.fracs[1])  # notice the frac!\n",
    "\n",
    "    plt.plot(x, y * plot_scaling, label=\"Sum - Model\", linewidth=linewidth * 2)\n",
    "    plt.plot(x, y_sig * plot_scaling, '--', label=f\"{model.pdfs[0].name} - Signal\", linewidth=linewidth)\n",
    "    plt.plot(x, y_bkg * plot_scaling, '--', label=f\"{model.pdfs[1].name} - Background\", linewidth=linewidth)\n",
    "    plt.xlabel(space.obs[0])\n",
    "    plt.legend()\n",
    "    \n",
    "\n",
    "plot_pdf_data(data=rare_data, model=model_rare, title='before fitting: $B^0 -> K^{*} (-> K^+ \\pi^-) \\mu^+ \\mu^-$')\n",
    "plt.show()\n",
    "\n",
    "# As a next step, the loss is created: the minimum of it defines the solution to the problem\n",
    "ext_rare_nll = zfit.loss.ExtendedUnbinnedNLL(model_rare, rare_data)\n",
    "\n",
    "# The minimization uses by default all floating parameters (that the model(s) used in the loss depend on)\n",
    "# but they can also be explicitly specified as an argument to `minimize`.\n",
    "result_rare = minimizer.minimize(ext_rare_nll)\n",
    "\n",
    "# The parameter values are set automatically to the value found at the minimum.\n",
    "plot_pdf_data(data=rare_data, model=model_rare, title='after rare fitting: $B^0 -> K^{*} (-> K^+ \\pi^-) \\mu^+ \\mu^-$')\n",
    "plt.show()\n",
    "# The information about the minimization and the result of it are stored in the\n",
    "# FitResult that is returned. It contains e.g. information about the parameters\n",
    "pprint(result_rare.params)\n",
    "\n",
    "# ...and more:\n",
    "print(f\"The fit converged: {result_rare.converged}, the minimum is {result_rare.fmin}\")\n",
    "\n",
    "# Following are error estimations. They return the result and also add it into the `params` attribute.\n",
    "# Unfortunately, hesse is currently not yet supported with weights.\n",
    "# result_rare.hesse()  # error calculation using the inverse hessian approximation\n",
    "# result_rare.error()  # error calculation using minos, this takes all parameters (expensive)\n",
    "result_rare.error([rare_sig_yield, mu])  # just for specific parameters\n",
    "pprint(result_rare.params)\n",
    "\n",
    "# the params can be accesssed using the parameter objects (not their names!)\n",
    "mu_rare_fit = result_rare.params[mu]\n",
    "# they contain information about the result such as value etc\n",
    "print(f\"Mu value of rare fit: {mu_rare_fit['value']} \"\n",
    "      f\"+ {mu_rare_fit['minuit_minos']['upper']} \"\n",
    "      f\"- {mu_rare_fit['minuit_minos']['upper']}\"\n",
    "      # f\" (symmetric Hesse error: {mu_rare_fit['minuit_hesse']['error']})\"\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Phasespace generation of the resonant decay**\n",
    "\n",
    "Since the previous fit, e.g. the tail, was not great due to the lack of statistics, we can also fit the resonant mode simultaneously and share certain parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the resonant decay. This is basically the same as above, we simply add an intermediate Jpsi.\n",
    "bz = GenParticle('B0', B0_MASS).set_children(kstar,\n",
    "                                             GenParticle('Jpsi', mass=JPSI_MASS).set_children(\n",
    "                                                 GenParticle('mu+', mass=MU_MASS),\n",
    "                                                 GenParticle('mu-', mass=MU_MASS)\n",
    "                                             ))\n",
    "\n",
    "weights_reso, particles_reso = bz.generate(n_sig_reso)\n",
    "weights_reso /= np.average(weights_reso)\n",
    "\n",
    "smeared_momenta_reso = {}\n",
    "daugther_particles_reso = ['K+', 'pi-', 'mu+', 'mu-']\n",
    "for particle in daugther_particles_reso:\n",
    "    smeared_momenta_reso[particle] = smear_momenta(particles_reso[particle], smearing=reso_smearing)\n",
    "\n",
    "smeared_momenta_reso['K*0'] = smeared_momenta_reso['K+'] + smeared_momenta_reso['pi-']\n",
    "smeared_momenta_reso['Jpsi'] = smeared_momenta_reso['mu+'] + smeared_momenta_reso['mu-']\n",
    "smeared_momenta_reso['B0'] = smeared_momenta_reso['K*0'] + smeared_momenta_reso['Jpsi']\n",
    "\n",
    "b_mass_reso = invariant_mass(smeared_momenta_reso['B0'])\n",
    "q2_reso = invariant_mass(smeared_momenta_reso['Jpsi'])\n",
    "\n",
    "# plot the q2\n",
    "plt.figure()\n",
    "plt.title(\"q2 generated resonant\")\n",
    "plt.hist(q2_reso, weights=weights_reso, alpha=0.5, bins=40, label=\"with weights\")\n",
    "plt.hist(q2_reso, bins=40, alpha=0.5, label=\"no weights\")\n",
    "plt.legend()\n",
    "\n",
    "# ------------------------------------------------\n",
    "# COMBINATORIAL BACKGROUND RESO\n",
    "# ------------------------------------------------\n",
    "\n",
    "lambda_reso = zfit.Parameter('lambda_reso', -0.002, -0.01, 0.0001)  # floating, also without limits\n",
    "comb_bkg_reso_pdf = zfit.pdf.Exponential(lambda_reso, obs=obs)\n",
    "\n",
    "# Create some more bkg data\n",
    "comb_bkg_reso_sample = comb_bkg_reso_pdf.sample(n=n_bkg_reso)  # sampled within the limits of `obs`\n",
    "\n",
    "# Set the value of lambda to smth different then we sampled from (for the fit afterwards)\n",
    "lambda_reso.set_value(-0.01)\n",
    "\n",
    "reso_data_np = np.concatenate([b_mass_reso, comb_bkg_reso_sample[:, 0]], axis=0)\n",
    "reso_weights_np = np.concatenate([weights_reso, np.ones_like(comb_bkg_reso_sample[:, 0])], axis=0)\n",
    "\n",
    "reso_data = zfit.Data.from_numpy(obs=obs, array=reso_data_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualise the spectrum:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (maybe remove plot, just for data visualization example?)\n",
    "plt.figure()\n",
    "plt.title(\"Invariant B mass $B^0 -> K^{*} (-> K^+ \\pi^-) J/\\psi (-> \\mu^+ \\mu^-)$\")\n",
    "plt.hist(reso_data_np, weights=reso_weights_np, bins=40)\n",
    "plt.xlabel(xlabel_bmass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# RESONANT MODEL\n",
    "# ------------------------------------------------\n",
    "\n",
    "# create the model to fit\n",
    "\n",
    "# we can share parameters directly or create composed parameters. Here we have a\n",
    "# parameter that scales the sigma from the rare fit\n",
    "\n",
    "sigma_scaling = zfit.Parameter('sigma_scaling', 0.9, 0.1, 10, step_size=0.1)\n",
    "\n",
    "\n",
    "def sigma_scaled_fn():\n",
    "    return sigma * sigma_scaling  # this can be an arbitrary function\n",
    "\n",
    "\n",
    "sigma_scaled = zfit.ComposedParameter('sigma scaled', sigma_scaled_fn,\n",
    "                                      dependents=sigma  # the objects used inside the function\n",
    "                                      )\n",
    "\n",
    "# Insead of sharing, free parameters could be used. This would though defy the purpose of the\n",
    "# simultaneous fit here. If we know that some can't be shared though (e.g. the tails between a \n",
    "# muon and electron modes), only certain parameters can be shared.\n",
    "# alphal_reso = zfit.Parameter('alpha left reso', -0.7, -5, 0)\n",
    "# nl_reso = zfit.Parameter('n left reso', 0.4, 0, 10)\n",
    "# alphar_reso = zfit.Parameter('alpha right reso', 1, 0, 5)\n",
    "# nr_reso = zfit.Parameter('n right reso', 1.8, 0, 10)\n",
    "\n",
    "alphal_reso = alphal_rare\n",
    "nl_reso = nl_rare\n",
    "alphar_reso = alphal_rare\n",
    "nr_reso = nr_rare\n",
    "\n",
    "# frac_dcb_reso = zfit.Parameter('frac dcb_reso', 0.5, 0.01, 0.99)\n",
    "frac_dcb_reso = frac_dcb_rare\n",
    "left_cb_reso = zfit.pdf.CrystalBall(obs=obs,\n",
    "                                    mu=mu, sigma=sigma_scaled,\n",
    "                                    alpha=alphal_reso, n=nl_reso,\n",
    "                                    )\n",
    "right_cb_reso = zfit.pdf.CrystalBall(obs=obs,\n",
    "                                     mu=mu, sigma=sigma_scaled,\n",
    "                                     alpha=alphar_reso, n=nr_reso,\n",
    "                                     )\n",
    "signal_reso = zfit.pdf.SumPDF([left_cb_reso, right_cb_reso], fracs=frac_dcb_reso)\n",
    "\n",
    "# Again, also a simpler (or custom) shape could be used\n",
    "# signal_reso = zfit.pdf.Gauss(mu=mu,  # using the same mu as above means it's shared\n",
    "#                              sigma=sigma_scaled, obs=obs)\n",
    "\n",
    "reso_sig_yield = zfit.Parameter('reso_sig_yield', n_sig_reso - 100, 0, n_sig_reso * 3,\n",
    "                                step_size=1)  # step size: default is small, use appropriate\n",
    "reso_bkg_yield = zfit.Parameter('reso_bkg_yield', n_bkg_reso + 70, 0, n_bkg_reso * 3, step_size=1)\n",
    "\n",
    "# Create the extended models\n",
    "extended_sig_reso = signal_reso.create_extended(reso_sig_yield)\n",
    "extended_bkg_reso = comb_bkg_reso_pdf.create_extended(reso_bkg_yield)\n",
    "model_reso = zfit.pdf.SumPDF([extended_bkg_reso, extended_sig_reso])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Simultaneous fit**\n",
    "\n",
    "- Built the simultaneous loss function.\n",
    "- Run the simultaneous fit.\n",
    "- Print and plot the fit results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraints could also be added to the loss, we don't have a good use-case here, so we leave them away.\n",
    "# They usually resemble other measurements of a parameter with an uncertainty in the same order of\n",
    "# magnitude as the sensitivity of our fit. Too strong constraint parameters can be though of as constants,\n",
    "# too loose do not add anything.\n",
    "# constraint = zfit.constraint.GaussianConstraint(mu, observation=5279, uncertainty=50)\n",
    "# ext_reso_nll = zfit.loss.ExtendedUnbinnedNLL(model_reso, reso_data, constraints=constraint)\n",
    "\n",
    "ext_reso_nll = zfit.loss.ExtendedUnbinnedNLL(model_reso, reso_data)\n",
    "\n",
    "# to create a simultaneous loss, the individual losses are added\n",
    "simultaneous_loss = ext_reso_nll + ext_rare_nll\n",
    "\n",
    "result_simult = minimizer.minimize(simultaneous_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pdf_data(data=rare_data, model=model_rare, title='$B^0 -> K^{*} (-> K^+ \\pi^-) \\mu^+ \\mu^-$')\n",
    "plot_pdf_data(data=reso_data, model=model_reso, title='$B^0 -> K^{*} (-> K^+ \\pi^-) J/\\psi (-> \\mu^+ \\mu^-)$')\n",
    "plt.show()\n",
    "\n",
    "# Hesse is not yet supported with weights\n",
    "# result_simult.hesse()  # error calculation using hesse\n",
    "errors = result_simult.error([mu, rare_sig_yield, reso_sig_yield])  # error calculation using minos, just for a few\n",
    "# parameters as it is quite expensive\n",
    "pprint(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. Wrapping up - determination of the signal significance**\n",
    "\n",
    "Going beyond the fits one is often interested in obtaining limits or calculate signal significances.\n",
    "These statistical procedures usually perform multiple fits with certain parameters fixed.\n",
    "\n",
    "For this purpose, the `bhepstats` library can be used. It is built on top of the same interface that `zfit`\n",
    "uses and therefore integrates well together. Models built and fits done in `zfit` will direclty work with `hepstats`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: maybe expand on discoveries and p-values etc? Not sure how it best fits into the overall\n",
    "# picture of the tutorial, you may have more on statistics somewhere else?\n",
    "\n",
    "# using hepstats\n",
    "from hepstats.hypotests import Discovery\n",
    "from hepstats.hypotests.calculators import AsymptoticCalculator\n",
    "from hepstats.hypotests.parameters import POI\n",
    "\n",
    "calculator = AsymptoticCalculator(simultaneous_loss, minimizer)\n",
    "poinull = POI(rare_sig_yield, 0)\n",
    "discovery_test = Discovery(calculator, poinull)\n",
    "pnull, significance = discovery_test.result()\n",
    "print(f'pnull: {pnull} with significance {significance}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "## **Final remarks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "<b>Scikit-HEP: built by the community</b>\n",
    "\n",
    "The ecosystem that is shown here is already advanced enough to perform analysis in it, as demonstrated in this tutorials. All this packages, including zfit, are written and maintained by other physicist or scientists in general. As any other library, they are neither perfect (bugfree) nor do they have all the features that you may want. They are however built for simple contribution: if there are missing features or bugs, please report or directly contribute them yourself and become part of the ecosystem.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
